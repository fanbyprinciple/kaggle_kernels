{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"from https://www.kaggle.com/code/jhoward/iterate-like-a-grandmaster/notebook","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport os\n\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n\nif iskaggle:\n    !pip install -Uqq fastai\n\nelse :\n    import zipfile, kaggle\n    path = Path('us-patent-phrase-to-phrase-matching')\n    kaggle.api.competition_download_cli(str(path))\n    zipfile.ZipFile(f'{path}.zip').extractall(path)","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:02.153207Z","iopub.execute_input":"2022-07-31T04:40:02.153568Z","iopub.status.idle":"2022-07-31T04:40:17.437953Z","shell.execute_reply.started":"2022-07-31T04:40:02.153537Z","shell.execute_reply":"2022-07-31T04:40:17.436406Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"\n\nA lot of the basic imports you'll want (np, pd, plt, etc) are provided by fastai, so let's grab them in one line:\n","metadata":{}},{"cell_type":"code","source":"from fastai.imports import *","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:17.444076Z","iopub.execute_input":"2022-07-31T04:40:17.446300Z","iopub.status.idle":"2022-07-31T04:40:17.646360Z","shell.execute_reply.started":"2022-07-31T04:40:17.446255Z","shell.execute_reply":"2022-07-31T04:40:17.645222Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Import and EDA","metadata":{}},{"cell_type":"code","source":"if iskaggle: path = Path('../input/us-patent-phrase-to-phrase-matching')\npath.ls()","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:17.652033Z","iopub.execute_input":"2022-07-31T04:40:17.654649Z","iopub.status.idle":"2022-07-31T04:40:17.669618Z","shell.execute_reply.started":"2022-07-31T04:40:17.654608Z","shell.execute_reply":"2022-07-31T04:40:17.668417Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(#3) [Path('../input/us-patent-phrase-to-phrase-matching/sample_submission.csv'),Path('../input/us-patent-phrase-to-phrase-matching/train.csv'),Path('../input/us-patent-phrase-to-phrase-matching/test.csv')]"},"metadata":{}}]},{"cell_type":"markdown","source":"Lets look at training set","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(path/'train.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:17.676486Z","iopub.execute_input":"2022-07-31T04:40:17.679112Z","iopub.status.idle":"2022-07-31T04:40:17.811679Z","shell.execute_reply.started":"2022-07-31T04:40:17.679075Z","shell.execute_reply":"2022-07-31T04:40:17.810703Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                     id        anchor                  target context  score\n0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50\n1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75\n2      36d72442aefd8232     abatement         active catalyst     A47   0.25\n3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50\n4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00\n...                 ...           ...                     ...     ...    ...\n36468  8e1386cbefd7f245  wood article          wooden article     B44   1.00\n36469  42d9e032d1cd3242  wood article              wooden box     B44   0.50\n36470  208654ccb9e14fa3  wood article           wooden handle     B44   0.50\n36471  756ec035e694722b  wood article         wooden material     B44   0.75\n36472  8d135da0b55b8c88  wood article        wooden substrate     B44   0.50\n\n[36473 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>37d61fd2272659b1</td>\n      <td>abatement</td>\n      <td>abatement of pollution</td>\n      <td>A47</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7b9652b17b68b7a4</td>\n      <td>abatement</td>\n      <td>act of abating</td>\n      <td>A47</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>36d72442aefd8232</td>\n      <td>abatement</td>\n      <td>active catalyst</td>\n      <td>A47</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5296b0c19e1ce60e</td>\n      <td>abatement</td>\n      <td>eliminating process</td>\n      <td>A47</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54c1e3b9184cb5b6</td>\n      <td>abatement</td>\n      <td>forest region</td>\n      <td>A47</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36468</th>\n      <td>8e1386cbefd7f245</td>\n      <td>wood article</td>\n      <td>wooden article</td>\n      <td>B44</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>36469</th>\n      <td>42d9e032d1cd3242</td>\n      <td>wood article</td>\n      <td>wooden box</td>\n      <td>B44</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>36470</th>\n      <td>208654ccb9e14fa3</td>\n      <td>wood article</td>\n      <td>wooden handle</td>\n      <td>B44</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>36471</th>\n      <td>756ec035e694722b</td>\n      <td>wood article</td>\n      <td>wooden material</td>\n      <td>B44</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>36472</th>\n      <td>8d135da0b55b8c88</td>\n      <td>wood article</td>\n      <td>wooden substrate</td>\n      <td>B44</td>\n      <td>0.50</td>\n    </tr>\n  </tbody>\n</table>\n<p>36473 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"this is the test set","metadata":{}},{"cell_type":"code","source":"eval_df = pd.read_csv(path/'test.csv')\nlen(eval_df)","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:17.813105Z","iopub.execute_input":"2022-07-31T04:40:17.813455Z","iopub.status.idle":"2022-07-31T04:40:17.825842Z","shell.execute_reply.started":"2022-07-31T04:40:17.813419Z","shell.execute_reply":"2022-07-31T04:40:17.824669Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"36"},"metadata":{}}]},{"cell_type":"code","source":"eval_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:17.827131Z","iopub.execute_input":"2022-07-31T04:40:17.827597Z","iopub.status.idle":"2022-07-31T04:40:17.840541Z","shell.execute_reply.started":"2022-07-31T04:40:17.827559Z","shell.execute_reply":"2022-07-31T04:40:17.839480Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                 id              anchor                         target context\n0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02\n1  09e418c93a776564     adjust gas flow              altering gas flow     F23\n2  36baf228038e314b      lower trunnion                 lower locating     B60\n3  1f37ead645e7f0c8       cap component                  upper portion     D06\n4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4112d61851461f60</td>\n      <td>opc drum</td>\n      <td>inorganic photoconductor drum</td>\n      <td>G02</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>09e418c93a776564</td>\n      <td>adjust gas flow</td>\n      <td>altering gas flow</td>\n      <td>F23</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>36baf228038e314b</td>\n      <td>lower trunnion</td>\n      <td>lower locating</td>\n      <td>B60</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1f37ead645e7f0c8</td>\n      <td>cap component</td>\n      <td>upper portion</td>\n      <td>D06</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>71a5b6ad068d531f</td>\n      <td>neural stimulation</td>\n      <td>artificial neural network</td>\n      <td>H04</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"looking at values of various fields","metadata":{}},{"cell_type":"code","source":"df.target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:17.842020Z","iopub.execute_input":"2022-07-31T04:40:17.842262Z","iopub.status.idle":"2022-07-31T04:40:17.873148Z","shell.execute_reply.started":"2022-07-31T04:40:17.842240Z","shell.execute_reply":"2022-07-31T04:40:17.872127Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"composition                    24\ndata                           22\nmetal                          22\nmotor                          22\nassembly                       21\n                               ..\nswitching switch over valve     1\nswitching switch off valve      1\nswitching over valve            1\nswitching off valve             1\nwooden substrate                1\nName: target, Length: 29340, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"\n\nWe see that there's nearly as many unique targets as items in the training set, so they're nearly but not quite unique. Most importantly, we can see that these generally contain very few words (1-4 words in the above sample).\n\nLet's check anchor:\n","metadata":{}},{"cell_type":"code","source":"df.anchor.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:17.874701Z","iopub.execute_input":"2022-07-31T04:40:17.875135Z","iopub.status.idle":"2022-07-31T04:40:17.889927Z","shell.execute_reply.started":"2022-07-31T04:40:17.875098Z","shell.execute_reply":"2022-07-31T04:40:17.888282Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"component composite coating              152\nsheet supply roller                      150\nsource voltage                           140\nperfluoroalkyl group                     136\nel display                               135\n                                        ... \nplug nozzle                                2\nshannon                                    2\ndry coating composition1                   2\nperipheral nervous system stimulation      1\nconduct conducting material                1\nName: anchor, Length: 733, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"\n\nWe can see here that there's far fewer unique values (just 733) and that again they're very short (2-4 words in this sample).\n\nNow we'll do context\n","metadata":{}},{"cell_type":"code","source":"df.context.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:17.892846Z","iopub.execute_input":"2022-07-31T04:40:17.893139Z","iopub.status.idle":"2022-07-31T04:40:17.906142Z","shell.execute_reply.started":"2022-07-31T04:40:17.893116Z","shell.execute_reply":"2022-07-31T04:40:17.905063Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"H01    2186\nH04    2177\nG01    1812\nA61    1477\nF16    1091\n       ... \nB03      47\nF17      33\nB31      24\nA62      23\nF26      18\nName: context, Length: 106, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"These are just short codes. Some of them have very few examples (18 in the smallest case) The first character is the section the patent was filed under -- let's create a column for that and look at the distribution","metadata":{}},{"cell_type":"code","source":"df['section'] = df.context.str[0]\ndf.section.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:17.910868Z","iopub.execute_input":"2022-07-31T04:40:17.911391Z","iopub.status.idle":"2022-07-31T04:40:17.951637Z","shell.execute_reply.started":"2022-07-31T04:40:17.911366Z","shell.execute_reply":"2022-07-31T04:40:17.950740Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"B    8019\nH    6195\nG    6013\nC    5288\nA    4094\nF    4054\nE    1531\nD    1279\nName: section, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"\n\nIt seems likely that these sections might be useful, since they've got quite a bit more data in each.\n\nFinally, we'll take a look at a histogram of the scores:\n","metadata":{}},{"cell_type":"code","source":"df.score.hist()","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:17.953227Z","iopub.execute_input":"2022-07-31T04:40:17.953873Z","iopub.status.idle":"2022-07-31T04:40:18.170846Z","shell.execute_reply.started":"2022-07-31T04:40:17.953838Z","shell.execute_reply":"2022-07-31T04:40:18.169576Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"df[df.score==1]","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:18.172081Z","iopub.execute_input":"2022-07-31T04:40:18.172700Z","iopub.status.idle":"2022-07-31T04:40:18.198104Z","shell.execute_reply.started":"2022-07-31T04:40:18.172664Z","shell.execute_reply":"2022-07-31T04:40:18.197202Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                     id                anchor                     target  \\\n28     473137168ebf7484             abatement                    abating   \n158    621b048d70aa8867  absorbent properties  absorbent characteristics   \n161    bc20a1c961cb073a  absorbent properties      absorption properties   \n311    e955700dffd68624       acid absorption         absorption of acid   \n315    3a09aba546aac675       acid absorption            acid absorption   \n...                 ...                   ...                        ...   \n36398  913141526432f1d6         wiring trough             wiring troughs   \n36435  ee0746f2a8ecef97          wood article              wood articles   \n36440  ecaf479135cf0dfd          wood article             wooden article   \n36464  8ceaa2b5c2d56250          wood article               wood article   \n36468  8e1386cbefd7f245          wood article             wooden article   \n\n      context  score section  \n28        F24    1.0       F  \n158       D01    1.0       D  \n161       D01    1.0       D  \n311       B08    1.0       B  \n315       B08    1.0       B  \n...       ...    ...     ...  \n36398     F16    1.0       F  \n36435     B05    1.0       B  \n36440     B05    1.0       B  \n36464     B44    1.0       B  \n36468     B44    1.0       B  \n\n[1154 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n      <th>score</th>\n      <th>section</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>28</th>\n      <td>473137168ebf7484</td>\n      <td>abatement</td>\n      <td>abating</td>\n      <td>F24</td>\n      <td>1.0</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>158</th>\n      <td>621b048d70aa8867</td>\n      <td>absorbent properties</td>\n      <td>absorbent characteristics</td>\n      <td>D01</td>\n      <td>1.0</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>161</th>\n      <td>bc20a1c961cb073a</td>\n      <td>absorbent properties</td>\n      <td>absorption properties</td>\n      <td>D01</td>\n      <td>1.0</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>311</th>\n      <td>e955700dffd68624</td>\n      <td>acid absorption</td>\n      <td>absorption of acid</td>\n      <td>B08</td>\n      <td>1.0</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>315</th>\n      <td>3a09aba546aac675</td>\n      <td>acid absorption</td>\n      <td>acid absorption</td>\n      <td>B08</td>\n      <td>1.0</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36398</th>\n      <td>913141526432f1d6</td>\n      <td>wiring trough</td>\n      <td>wiring troughs</td>\n      <td>F16</td>\n      <td>1.0</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>36435</th>\n      <td>ee0746f2a8ecef97</td>\n      <td>wood article</td>\n      <td>wood articles</td>\n      <td>B05</td>\n      <td>1.0</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>36440</th>\n      <td>ecaf479135cf0dfd</td>\n      <td>wood article</td>\n      <td>wooden article</td>\n      <td>B05</td>\n      <td>1.0</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>36464</th>\n      <td>8ceaa2b5c2d56250</td>\n      <td>wood article</td>\n      <td>wood article</td>\n      <td>B44</td>\n      <td>1.0</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>36468</th>\n      <td>8e1386cbefd7f245</td>\n      <td>wood article</td>\n      <td>wooden article</td>\n      <td>B44</td>\n      <td>1.0</td>\n      <td>B</td>\n    </tr>\n  </tbody>\n</table>\n<p>1154 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"\n\nWe can see from this that these are just minor rewordings of the same concept, and isn't likely to be specific to context. Any pretrained model should be pretty good at finding these already.\n","metadata":{}},{"cell_type":"markdown","source":"# training","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport warnings, transformers, logging, torch\nfrom transformers import TrainingArguments, Trainer\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:18.199452Z","iopub.execute_input":"2022-07-31T04:40:18.200012Z","iopub.status.idle":"2022-07-31T04:40:26.399629Z","shell.execute_reply.started":"2022-07-31T04:40:18.199973Z","shell.execute_reply":"2022-07-31T04:40:26.398587Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"if iskaggle:\n    !pip install -q datasets\nimport datasets\nfrom datasets import load_dataset, Dataset, DatasetDict","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:26.402434Z","iopub.execute_input":"2022-07-31T04:40:26.403835Z","iopub.status.idle":"2022-07-31T04:40:36.425403Z","shell.execute_reply.started":"2022-07-31T04:40:26.403789Z","shell.execute_reply":"2022-07-31T04:40:36.424286Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"\n\nHuggingFace Transformers tends to be rather enthusiastic about spitting out lots of warnings, so let's quieten it down for our sanity:\n","metadata":{}},{"cell_type":"code","source":"warnings.simplefilter('ignore')\nlogging.disable(logging.WARNING)","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:36.427160Z","iopub.execute_input":"2022-07-31T04:40:36.428098Z","iopub.status.idle":"2022-07-31T04:40:36.434975Z","shell.execute_reply.started":"2022-07-31T04:40:36.428065Z","shell.execute_reply":"2022-07-31T04:40:36.433913Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"\n\nI tried to find a model that I could train reasonably at home in under two minutes, but got reasonable accuracy from. I found that deberta-v3-small fits the bill, so let's use it:\n","metadata":{}},{"cell_type":"code","source":"model_nm = 'microsoft/deberta-v3-small'","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:36.436445Z","iopub.execute_input":"2022-07-31T04:40:36.437430Z","iopub.status.idle":"2022-07-31T04:40:36.445354Z","shell.execute_reply.started":"2022-07-31T04:40:36.437400Z","shell.execute_reply":"2022-07-31T04:40:36.444413Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"We can now create a tokenizer for this model. Note that pretrained models assume that text is tokenized in a particular way. In order to ensure that your tokenizer matches your model, use the AutoTokenizer, passing in your model name.","metadata":{}},{"cell_type":"code","source":"tokz = AutoTokenizer.from_pretrained(model_nm)","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:36.448343Z","iopub.execute_input":"2022-07-31T04:40:36.450170Z","iopub.status.idle":"2022-07-31T04:40:42.128385Z","shell.execute_reply.started":"2022-07-31T04:40:36.450036Z","shell.execute_reply":"2022-07-31T04:40:42.127531Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"963d8dff786348b09c406fb8343fdbf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/578 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffb92c1448eb4a6d83b1c51a9f8b0c5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a0bbdb0ab8f486d8966099dd2e5cf30"}},"metadata":{}}]},{"cell_type":"markdown","source":"We'll need to combine the context, anchor, and target together somehow. There's not much research as to the best way to do this, so we may need to iterate a bit. To start with, we'll just combine them all into a single string. The model will need to know where each section starts, so we can use the special separator token to tell it:","metadata":{}},{"cell_type":"code","source":"sep = tokz.sep_token\nsep","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:42.129842Z","iopub.execute_input":"2022-07-31T04:40:42.130186Z","iopub.status.idle":"2022-07-31T04:40:42.138278Z","shell.execute_reply.started":"2022-07-31T04:40:42.130148Z","shell.execute_reply":"2022-07-31T04:40:42.137428Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'[SEP]'"},"metadata":{}}]},{"cell_type":"code","source":"df['inputs'] = df.context + sep + df.anchor + sep + df.target","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:42.139773Z","iopub.execute_input":"2022-07-31T04:40:42.140644Z","iopub.status.idle":"2022-07-31T04:40:42.164608Z","shell.execute_reply.started":"2022-07-31T04:40:42.140605Z","shell.execute_reply":"2022-07-31T04:40:42.163768Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"looking at df","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-31T05:06:35.126632Z","iopub.execute_input":"2022-07-31T05:06:35.127433Z","iopub.status.idle":"2022-07-31T05:06:35.150234Z","shell.execute_reply.started":"2022-07-31T05:06:35.127384Z","shell.execute_reply":"2022-07-31T05:06:35.149297Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"                     id                             anchor  \\\n33511  ed1c4e525eb105fe                     transmit alarm   \n18670  5386316f318f5221                  locking formation   \n18049  1544ca6753fcbddd                      lateral power   \n31660  f9d8979b94cec923                      spreader body   \n15573  e151ca5ea5cc0f08  high gradient magnetic separators   \n\n                    target context  score section  \\\n33511    display indicator     G08   0.00       G   \n18670    retaining element     B60   0.25       B   \n18049           transducer     H01   0.25       H   \n31660             spreader     A01   0.75       A   \n15573  magnetic filtration     B03   0.50       B   \n\n                                                                          inputs  \\\n33511                       [G] [s] G08 [s] transmit alarm [s] display indicator   \n18670                    [B] [s] B60 [s] locking formation [s] retaining element   \n18049                               [H] [s] H01 [s] lateral power [s] transducer   \n31660                                 [A] [s] A01 [s] spreader body [s] spreader   \n15573  [B] [s] B03 [s] high gradient magnetic separators [s] magnetic filtration   \n\n      sectok  \n33511    [G]  \n18670    [B]  \n18049    [H]  \n31660    [A]  \n15573    [B]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anchor</th>\n      <th>target</th>\n      <th>context</th>\n      <th>score</th>\n      <th>section</th>\n      <th>inputs</th>\n      <th>sectok</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>33511</th>\n      <td>ed1c4e525eb105fe</td>\n      <td>transmit alarm</td>\n      <td>display indicator</td>\n      <td>G08</td>\n      <td>0.00</td>\n      <td>G</td>\n      <td>[G] [s] G08 [s] transmit alarm [s] display indicator</td>\n      <td>[G]</td>\n    </tr>\n    <tr>\n      <th>18670</th>\n      <td>5386316f318f5221</td>\n      <td>locking formation</td>\n      <td>retaining element</td>\n      <td>B60</td>\n      <td>0.25</td>\n      <td>B</td>\n      <td>[B] [s] B60 [s] locking formation [s] retaining element</td>\n      <td>[B]</td>\n    </tr>\n    <tr>\n      <th>18049</th>\n      <td>1544ca6753fcbddd</td>\n      <td>lateral power</td>\n      <td>transducer</td>\n      <td>H01</td>\n      <td>0.25</td>\n      <td>H</td>\n      <td>[H] [s] H01 [s] lateral power [s] transducer</td>\n      <td>[H]</td>\n    </tr>\n    <tr>\n      <th>31660</th>\n      <td>f9d8979b94cec923</td>\n      <td>spreader body</td>\n      <td>spreader</td>\n      <td>A01</td>\n      <td>0.75</td>\n      <td>A</td>\n      <td>[A] [s] A01 [s] spreader body [s] spreader</td>\n      <td>[A]</td>\n    </tr>\n    <tr>\n      <th>15573</th>\n      <td>e151ca5ea5cc0f08</td>\n      <td>high gradient magnetic separators</td>\n      <td>magnetic filtration</td>\n      <td>B03</td>\n      <td>0.50</td>\n      <td>B</td>\n      <td>[B] [s] B03 [s] high gradient magnetic separators [s] magnetic filtration</td>\n      <td>[B]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Generally we'll get best performance if we convert pandas DataFrames into HuggingFace Datasets, so we'll convert them over, and also rename the score column to what Transformers expects for the dependent variable, which is label:","metadata":{}},{"cell_type":"code","source":"ds = Dataset.from_pandas(df).rename_column('score', 'label')\neval_ds = Dataset.from_pandas(eval_df)","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:42.165881Z","iopub.execute_input":"2022-07-31T04:40:42.166199Z","iopub.status.idle":"2022-07-31T04:40:42.205054Z","shell.execute_reply.started":"2022-07-31T04:40:42.166165Z","shell.execute_reply":"2022-07-31T04:40:42.204234Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"ds[0]","metadata":{"execution":{"iopub.status.busy":"2022-07-31T05:12:47.161417Z","iopub.execute_input":"2022-07-31T05:12:47.162289Z","iopub.status.idle":"2022-07-31T05:12:47.169360Z","shell.execute_reply.started":"2022-07-31T05:12:47.162236Z","shell.execute_reply":"2022-07-31T05:12:47.168419Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"{'id': '37d61fd2272659b1',\n 'anchor': 'abatement',\n 'target': 'abatement of pollution',\n 'context': 'A47',\n 'label': 0.5,\n 'section': 'A',\n 'inputs': 'A47[SEP]abatement[SEP]abatement of pollution'}"},"metadata":{}}]},{"cell_type":"markdown","source":"\n\nTo tokenize the data, we'll create a function (since that's what Dataset.map will need):\n","metadata":{}},{"cell_type":"code","source":"def tok_func(x): \n    return tokz(x[\"inputs\"])","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:42.206217Z","iopub.execute_input":"2022-07-31T04:40:42.206445Z","iopub.status.idle":"2022-07-31T04:40:42.212575Z","shell.execute_reply.started":"2022-07-31T04:40:42.206413Z","shell.execute_reply":"2022-07-31T04:40:42.211472Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"Let's try tokenizing one input and see how it looks","metadata":{}},{"cell_type":"code","source":"tok_func(ds[0])","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:42.214154Z","iopub.execute_input":"2022-07-31T04:40:42.214414Z","iopub.status.idle":"2022-07-31T04:40:42.230460Z","shell.execute_reply.started":"2022-07-31T04:40:42.214380Z","shell.execute_reply":"2022-07-31T04:40:42.229648Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [1, 336, 5753, 2, 47284, 2, 47284, 265, 6435, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"markdown","source":"\n\nThe only bit we care about at the moment is input_ids. We can see in the tokens that it starts with a special token 1 (which represents the start of text), and then has our three fields separated by the separator token 2. We can check the indices of the special token IDs like so:\n","metadata":{}},{"cell_type":"code","source":"tokz.all_special_tokens","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:42.232023Z","iopub.execute_input":"2022-07-31T04:40:42.232819Z","iopub.status.idle":"2022-07-31T04:40:42.239703Z","shell.execute_reply.started":"2022-07-31T04:40:42.232780Z","shell.execute_reply":"2022-07-31T04:40:42.238716Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"['[CLS]', '[SEP]', '[UNK]', '[PAD]', '[MASK]']"},"metadata":{}}]},{"cell_type":"markdown","source":"We can now tokenize the input. We'll use batching to speed it up, and remove the columns we no longer need:","metadata":{}},{"cell_type":"code","source":"inps = \"anchor\", \"target\", \"context\"\ntok_ds = ds.map(tok_func, batched=True, remove_columns=inps+('inputs', 'id', 'section'))","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:42.241233Z","iopub.execute_input":"2022-07-31T04:40:42.241700Z","iopub.status.idle":"2022-07-31T04:40:44.114907Z","shell.execute_reply.started":"2022-07-31T04:40:42.241665Z","shell.execute_reply":"2022-07-31T04:40:44.113981Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/37 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b9618cd61344f2fb221e5de51c92987"}},"metadata":{}}]},{"cell_type":"code","source":"tok_ds[0]","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:44.116320Z","iopub.execute_input":"2022-07-31T04:40:44.117204Z","iopub.status.idle":"2022-07-31T04:40:44.127613Z","shell.execute_reply.started":"2022-07-31T04:40:44.117163Z","shell.execute_reply":"2022-07-31T04:40:44.126667Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"{'label': 0.5,\n 'input_ids': [1, 336, 5753, 2, 47284, 2, 47284, 265, 6435, 2],\n 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"markdown","source":"# creating a validation set","metadata":{}},{"cell_type":"markdown","source":"\n\nAccording to this post, the private test anchors do not overlap with the training set. So let's do the same thing for our validation set.\n\nFirst, create a randomly shuffled list of anchors:\n","metadata":{}},{"cell_type":"code","source":"anchors = df.anchor.unique()\nnp.random.seed(42)\nnp.random.shuffle(anchors)\nanchors[:5]","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:44.129026Z","iopub.execute_input":"2022-07-31T04:40:44.129673Z","iopub.status.idle":"2022-07-31T04:40:44.155827Z","shell.execute_reply.started":"2022-07-31T04:40:44.129634Z","shell.execute_reply":"2022-07-31T04:40:44.154824Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"array(['time digital signal', 'antiatherosclerotic', 'filled interior',\n       'dispersed powder', 'locking formation'], dtype=object)"},"metadata":{}}]},{"cell_type":"markdown","source":"\n\nNow we can pick some proportion (e.g 25%) of these anchors to go in the validation set:\n","metadata":{}},{"cell_type":"code","source":"val_prop = 0.25\nval_sz = int(len(anchors)*val_prop)\nval_anchors = anchors[:val_sz]","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:44.157473Z","iopub.execute_input":"2022-07-31T04:40:44.157936Z","iopub.status.idle":"2022-07-31T04:40:44.163302Z","shell.execute_reply.started":"2022-07-31T04:40:44.157898Z","shell.execute_reply":"2022-07-31T04:40:44.162246Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"\n\nNow we can get a list of which rows match val_anchors, and get their indices:\n","metadata":{}},{"cell_type":"code","source":"is_val = np.isin(df.anchor, val_anchors)\nidxs = np.arange(len(df))\nval_idxs = idxs[is_val]\ntrn_idxs = idxs[~is_val]\nlen(val_idxs), len(trn_idxs)","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:44.169885Z","iopub.execute_input":"2022-07-31T04:40:44.171735Z","iopub.status.idle":"2022-07-31T04:40:44.392613Z","shell.execute_reply.started":"2022-07-31T04:40:44.171702Z","shell.execute_reply":"2022-07-31T04:40:44.391457Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"(9116, 27357)"},"metadata":{}}]},{"cell_type":"markdown","source":"Our training and validation Datasets can now be selected, and put into a DatasetDict ready for training:","metadata":{}},{"cell_type":"code","source":"dds = DatasetDict({\"train\": tok_ds.select(trn_idxs), \n                   \"test\": tok_ds.select(val_idxs)})","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:44.394079Z","iopub.execute_input":"2022-07-31T04:40:44.394602Z","iopub.status.idle":"2022-07-31T04:40:44.416315Z","shell.execute_reply.started":"2022-07-31T04:40:44.394533Z","shell.execute_reply":"2022-07-31T04:40:44.415513Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"\n\nBTW, a lot of people do more complex stuff for creating their validation set, but with a dataset this large there's not much point. As you can see, the mean scores in the two groups are very similar despite just doing a random shuffle:\n","metadata":{}},{"cell_type":"code","source":"df.iloc[trn_idxs].score.mean(), df.iloc[val_idxs].score.mean()","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:44.418613Z","iopub.execute_input":"2022-07-31T04:40:44.419257Z","iopub.status.idle":"2022-07-31T04:40:44.438124Z","shell.execute_reply.started":"2022-07-31T04:40:44.419203Z","shell.execute_reply":"2022-07-31T04:40:44.436970Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"(0.3623021530138539, 0.3613426941641071)"},"metadata":{}}]},{"cell_type":"markdown","source":"# initial model","metadata":{}},{"cell_type":"markdown","source":"\n\nLet's now train our model! We'll need to specify a metric, which is the correlation coefficient provided by numpy (we need to return a dictionary since that's how Transformers knows what label to use):\n","metadata":{}},{"cell_type":"code","source":"def corr(eval_pred): return {'pearson': np.corrcoef(*eval_pred)[0][1]}","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:44.439828Z","iopub.execute_input":"2022-07-31T04:40:44.440160Z","iopub.status.idle":"2022-07-31T04:40:44.447568Z","shell.execute_reply.started":"2022-07-31T04:40:44.440123Z","shell.execute_reply":"2022-07-31T04:40:44.446624Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"\n\nWe pick a learning rate and batch size that fits our GPU, and pick a reasonable weight decay and small number of epochs:\n","metadata":{}},{"cell_type":"code","source":"lr, bs = 8e-5, 128\nwd, epochs = 0.01, 4","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:44.449271Z","iopub.execute_input":"2022-07-31T04:40:44.449560Z","iopub.status.idle":"2022-07-31T04:40:44.455811Z","shell.execute_reply.started":"2022-07-31T04:40:44.449525Z","shell.execute_reply":"2022-07-31T04:40:44.454637Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"\n\nThree epochs might not sound like much, but you'll see once we train that most of the progress can be made in that time, so this is good for experimentation.\n\nTransformers uses the TrainingArguments class to set up arguments. We'll use a cosine scheduler with warmup, since at fast.ai we've found that's pretty reliable. We'll use fp16 since it's much faster on modern GPUs, and saves some memory. We evaluate using double-sized batches, since no gradients are stored so we can do twice as many rows at a time.\n","metadata":{}},{"cell_type":"code","source":"def get_trainer(dds):\n    args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n        evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n        num_train_epochs=epochs, weight_decay=wd, report_to='none')\n    model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n    return Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n                   tokenizer=tokz, compute_metrics=corr)","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:44.457437Z","iopub.execute_input":"2022-07-31T04:40:44.457776Z","iopub.status.idle":"2022-07-31T04:40:44.466467Z","shell.execute_reply.started":"2022-07-31T04:40:44.457674Z","shell.execute_reply":"2022-07-31T04:40:44.465609Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,num_train_epochs=epochs, weight_decay=wd, report_to='none')","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:44.468078Z","iopub.execute_input":"2022-07-31T04:40:44.468344Z","iopub.status.idle":"2022-07-31T04:40:44.546711Z","shell.execute_reply.started":"2022-07-31T04:40:44.468307Z","shell.execute_reply":"2022-07-31T04:40:44.545842Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\ntrainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'], tokenizer=tokz, compute_metrics=corr)","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:44.548241Z","iopub.execute_input":"2022-07-31T04:40:44.548481Z","iopub.status.idle":"2022-07-31T04:40:57.877597Z","shell.execute_reply.started":"2022-07-31T04:40:44.548446Z","shell.execute_reply":"2022-07-31T04:40:57.876583Z"},"trusted":true},"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/273M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e71dcf3646247088e28752fa4367313"}},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:40:57.880556Z","iopub.execute_input":"2022-07-31T04:40:57.880832Z","iopub.status.idle":"2022-07-31T04:45:05.621764Z","shell.execute_reply.started":"2022-07-31T04:40:57.880796Z","shell.execute_reply":"2022-07-31T04:45:05.620804Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='856' max='856' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [856/856 04:06, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Pearson</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.028006</td>\n      <td>0.788895</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.025104</td>\n      <td>0.810376</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.037000</td>\n      <td>0.024000</td>\n      <td>0.817113</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.037000</td>\n      <td>0.024755</td>\n      <td>0.815944</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=856, training_loss=0.027186344160097783, metrics={'train_runtime': 247.7179, 'train_samples_per_second': 441.744, 'train_steps_per_second': 3.456, 'total_flos': 469191313065600.0, 'train_loss': 0.027186344160097783, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"# improving the model","metadata":{}},{"cell_type":"markdown","source":"\n\nWe now want to start iterating to improve this. To do that, we need to know whether the model gives stable results. I tried training it 3 times from scratch, and got a range of outcomes from 0.808-0.810. This is stable enough to make a start - if we're not finding improvements that are visible within this range, then they're not very significant! Later on, if and when we feel confident that we've got the basics right, we can use cross validation and more epochs of training.\n\nIteration speed is critical, so we need to quickly be able to try different data processing and trainer parameters. So let's create a function to quickly apply tokenization and create our DatasetDict:\n","metadata":{}},{"cell_type":"code","source":"\n\ndef get_dds(df):\n    ds = Dataset.from_pandas(df).rename_column('score', 'label')\n    tok_ds = ds.map(tok_func, batched=True, remove_columns=inps+('inputs','id','section'))\n    return DatasetDict({\"train\":tok_ds.select(trn_idxs), \"test\": tok_ds.select(val_idxs)})\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:45:05.624596Z","iopub.execute_input":"2022-07-31T04:45:05.624799Z","iopub.status.idle":"2022-07-31T04:45:05.630699Z","shell.execute_reply.started":"2022-07-31T04:45:05.624774Z","shell.execute_reply":"2022-07-31T04:45:05.629694Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"\n\n...and also a function to create a Trainer:\n","metadata":{}},{"cell_type":"code","source":"def get_model(): return AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n\ndef get_trainer(dds, model=None):\n    if model is None: model = get_model()\n    args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n        evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n        num_train_epochs=epochs, weight_decay=wd, report_to='none')\n    return Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n                   tokenizer=tokz, compute_metrics=corr)","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:45:05.632246Z","iopub.execute_input":"2022-07-31T04:45:05.632665Z","iopub.status.idle":"2022-07-31T04:45:05.647152Z","shell.execute_reply.started":"2022-07-31T04:45:05.632628Z","shell.execute_reply":"2022-07-31T04:45:05.646266Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"\n\nLet's now try out some ideas...\n\nPerhaps using the special separator character isn't a good idea, and we should use something we create instead. Let's see if that makes things better. First we'll change the separator and create the DatasetDict:\n","metadata":{}},{"cell_type":"code","source":"sep = \" [s] \"\ndf['inputs'] = df.context + sep + df.anchor + sep + df.target\ndds = get_dds(df)","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:45:05.650681Z","iopub.execute_input":"2022-07-31T04:45:05.650912Z","iopub.status.idle":"2022-07-31T04:45:07.583078Z","shell.execute_reply.started":"2022-07-31T04:45:05.650888Z","shell.execute_reply":"2022-07-31T04:45:07.582303Z"},"trusted":true},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/37 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a9dff337ee142758186343c66db7c4b"}},"metadata":{}}]},{"cell_type":"markdown","source":"\n\n...and create and train a model.\n","metadata":{}},{"cell_type":"code","source":"get_trainer(dds).train()","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:45:07.584381Z","iopub.execute_input":"2022-07-31T04:45:07.584900Z","iopub.status.idle":"2022-07-31T04:49:29.873850Z","shell.execute_reply.started":"2022-07-31T04:45:07.584859Z","shell.execute_reply":"2022-07-31T04:49:29.872875Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='856' max='856' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [856/856 04:19, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Pearson</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.024942</td>\n      <td>0.799117</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.025590</td>\n      <td>0.814783</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.031300</td>\n      <td>0.023194</td>\n      <td>0.820567</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.031300</td>\n      <td>0.024171</td>\n      <td>0.819860</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=856, training_loss=0.023601023950309396, metrics={'train_runtime': 259.9313, 'train_samples_per_second': 420.988, 'train_steps_per_second': 3.293, 'total_flos': 582440534448480.0, 'train_loss': 0.023601023950309396, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"\n\nThat's looking quite a bit better, so we'll keep that change.\n\nOften changing to lowercase is helpful. Let's see if that helps too:\n","metadata":{}},{"cell_type":"code","source":"df['inputs'] = df.inputs.str.lower()\ndds = get_dds(df)\nget_trainer(dds).train()","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:49:29.875490Z","iopub.execute_input":"2022-07-31T04:49:29.875764Z","iopub.status.idle":"2022-07-31T04:53:54.569398Z","shell.execute_reply.started":"2022-07-31T04:49:29.875728Z","shell.execute_reply":"2022-07-31T04:53:54.568562Z"},"trusted":true},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/37 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29d2962da4114f52b75f3b21d9d7a405"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='856' max='856' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [856/856 04:19, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Pearson</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.024730</td>\n      <td>0.799405</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.025684</td>\n      <td>0.813678</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.031500</td>\n      <td>0.023043</td>\n      <td>0.820755</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.031500</td>\n      <td>0.024291</td>\n      <td>0.819741</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=856, training_loss=0.023727591349699786, metrics={'train_runtime': 260.2759, 'train_samples_per_second': 420.431, 'train_steps_per_second': 3.289, 'total_flos': 582440534448480.0, 'train_loss': 0.023727591349699786, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"\n\nThat one is less clear. We'll keep that change too since most times I run it, it's a little better.\n","metadata":{}},{"cell_type":"markdown","source":"# creating our own special tokens","metadata":{}},{"cell_type":"code","source":"df['sectok'] = '[' + df.section + ']'\nsectoks = list(df.sectok.unique())\ntokz.add_special_tokens({'additional_special_tokens': sectoks})","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:53:54.573879Z","iopub.execute_input":"2022-07-31T04:53:54.574411Z","iopub.status.idle":"2022-07-31T04:53:54.594943Z","shell.execute_reply.started":"2022-07-31T04:53:54.574372Z","shell.execute_reply":"2022-07-31T04:53:54.594157Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"8"},"metadata":{}}]},{"cell_type":"markdown","source":"concatenating the section token to the start of our inputs","metadata":{}},{"cell_type":"code","source":"df['inputs'] = df.sectok + sep + df.context + sep + df.anchor.str.lower() + sep + df.target\ndds = get_dds(df)","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:53:54.596430Z","iopub.execute_input":"2022-07-31T04:53:54.596889Z","iopub.status.idle":"2022-07-31T04:53:57.143226Z","shell.execute_reply.started":"2022-07-31T04:53:54.596853Z","shell.execute_reply":"2022-07-31T04:53:57.142414Z"},"trusted":true},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/37 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c3998a9fe1848e597ec3b5112395011"}},"metadata":{}}]},{"cell_type":"markdown","source":"\n\nSince we've added more tokens, we need to resize the embedding matrix in the model:\n","metadata":{}},{"cell_type":"code","source":"\n\nmodel = get_model()\nmodel.resize_token_embeddings(len(tokz))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:53:57.144869Z","iopub.execute_input":"2022-07-31T04:53:57.145123Z","iopub.status.idle":"2022-07-31T04:54:01.269915Z","shell.execute_reply.started":"2022-07-31T04:53:57.145088Z","shell.execute_reply":"2022-07-31T04:54:01.268891Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"Embedding(128009, 768)"},"metadata":{}}]},{"cell_type":"markdown","source":"Now we are ready to train","metadata":{}},{"cell_type":"code","source":"trainer = get_trainer(dds, model=model)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:54:01.271510Z","iopub.execute_input":"2022-07-31T04:54:01.271770Z","iopub.status.idle":"2022-07-31T04:58:39.959200Z","shell.execute_reply.started":"2022-07-31T04:54:01.271735Z","shell.execute_reply":"2022-07-31T04:58:39.958352Z"},"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='856' max='856' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [856/856 04:38, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Pearson</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.024826</td>\n      <td>0.797162</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.025376</td>\n      <td>0.817938</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.031800</td>\n      <td>0.023239</td>\n      <td>0.822923</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.031800</td>\n      <td>0.023447</td>\n      <td>0.824512</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=856, training_loss=0.023839535557221028, metrics={'train_runtime': 278.5211, 'train_samples_per_second': 392.889, 'train_steps_per_second': 3.073, 'total_flos': 695689755831360.0, 'train_loss': 0.023839535557221028, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"Jeremy presents with many more ideas","metadata":{}},{"cell_type":"markdown","source":"\n\nIt looks like we've made another bit of an improvement!\n\nThere's plenty more things you could try. Here's some thoughts:\n\n    Try a model pretrained on legal vocabulary. E.g. how about BERT for patents?\n    You'd likely get better results by using a sentence similarity model. Did you know that there's a patent similarity model you could try?\n    You could also fine-tune any HuggingFace model using the full patent database (which is provided in BigQuery), before applying it to this dataset\n    Replace the patent context field with the description of that context provided by the patent office\n    ...and try out your own ideas too!\n\nBefore submitting a model, retrain it on the full dataset, rather than just the 75% training subset we've used here. Create a function like the ones above to make that easy for you!\"\n","metadata":{}},{"cell_type":"markdown","source":"# cross validation","metadata":{}},{"cell_type":"code","source":"n_folds =4","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:58:39.960648Z","iopub.execute_input":"2022-07-31T04:58:39.961123Z","iopub.status.idle":"2022-07-31T04:58:39.965962Z","shell.execute_reply.started":"2022-07-31T04:58:39.961085Z","shell.execute_reply":"2022-07-31T04:58:39.964848Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"\n\nOnce you've gotten the low hanging fruit, you might want to use cross-validation to see the impact of minor changes. This time we'll use StratifiedGroupKFold, partly just to show a different approach to before, and partly because it will give us slightly better balanced datasets.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedGroupKFold\ncv = StratifiedGroupKFold(n_splits=n_folds)","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:58:39.967339Z","iopub.execute_input":"2022-07-31T04:58:39.967861Z","iopub.status.idle":"2022-07-31T04:58:39.988378Z","shell.execute_reply.started":"2022-07-31T04:58:39.967826Z","shell.execute_reply":"2022-07-31T04:58:39.987567Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"\n\nHere's how to split the data frame into n_folds groups, with non-overlapping anchors and matched scores, after randomly shuffling the rows:\n","metadata":{}},{"cell_type":"code","source":"\n\ndf = df.sample(frac=1, random_state=42)\nscores = (df.score*100).astype(int)\nfolds = list(cv.split(idxs, scores, df.anchor))\nfolds\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:58:39.990602Z","iopub.execute_input":"2022-07-31T04:58:39.991074Z","iopub.status.idle":"2022-07-31T04:58:40.357181Z","shell.execute_reply.started":"2022-07-31T04:58:39.991038Z","shell.execute_reply":"2022-07-31T04:58:40.356236Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"[(array([    0,     1,     2, ..., 36469, 36471, 36472]),\n  array([    8,    13,    14, ..., 36453, 36464, 36470])),\n (array([    0,     1,     5, ..., 36470, 36471, 36472]),\n  array([    2,     3,     4, ..., 36459, 36461, 36462])),\n (array([    1,     2,     3, ..., 36467, 36470, 36472]),\n  array([    0,     7,    11, ..., 36468, 36469, 36471])),\n (array([    0,     2,     3, ..., 36469, 36470, 36471]),\n  array([    1,     5,     9, ..., 36465, 36467, 36472]))]"},"metadata":{}}]},{"cell_type":"markdown","source":"\n\nWe can now create a little function to split into training and validation sets based on a fold:\n","metadata":{}},{"cell_type":"code","source":"\n\ndef get_fold(folds, fold_num):\n    trn,val = folds[fold_num]\n    return DatasetDict({\"train\":tok_ds.select(trn), \"test\": tok_ds.select(val)})\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:58:40.358673Z","iopub.execute_input":"2022-07-31T04:58:40.359152Z","iopub.status.idle":"2022-07-31T04:58:40.365533Z","shell.execute_reply.started":"2022-07-31T04:58:40.359112Z","shell.execute_reply":"2022-07-31T04:58:40.364423Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"Lets try it out","metadata":{}},{"cell_type":"code","source":"dds = get_fold(folds, 0)\ndds","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:58:40.367315Z","iopub.execute_input":"2022-07-31T04:58:40.367586Z","iopub.status.idle":"2022-07-31T04:58:40.394573Z","shell.execute_reply.started":"2022-07-31T04:58:40.367552Z","shell.execute_reply":"2022-07-31T04:58:40.393763Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 27346\n    })\n    test: Dataset({\n        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 9127\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"\n\nWe can now pass this into get_trainer as we did before. If we have, say, 4 folds, then doing that for each fold will give us 4 models, and 4 sets of predictions and metrics. You could ensemble the 4 models to get a stronger model, and can also average the 4 metrics to get a more accurate assessment of your model. Here's how to get the final epoch metrics from a trainer:\n","metadata":{}},{"cell_type":"code","source":"metrics = [o['eval_pearson'] for o in trainer.state.log_history if 'eval_pearson' in o]\nmetrics[-1]","metadata":{"execution":{"iopub.status.busy":"2022-07-31T04:58:40.397305Z","iopub.execute_input":"2022-07-31T04:58:40.397561Z","iopub.status.idle":"2022-07-31T04:58:40.406663Z","shell.execute_reply.started":"2022-07-31T04:58:40.397535Z","shell.execute_reply":"2022-07-31T04:58:40.405535Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"0.8245123117960352"},"metadata":{}}]}]}